import asyncio,websockets, logging,json
from decimal import Decimal # YENÄ°
from backend.trade_engine import config
from backend.trade_engine import config
from backend.trade_engine.balance.db.stream_key_db import attach_listenkeys_to_ws
from backend.trade_engine.balance.db import ws_db
from backend.trade_engine.balance.db.futures_writer_db import batch_upsert_futures_balances, batch_upsert_futures_orders
from backend.trade_engine.taha_part.utils.price_cache_new import get_price


logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class Deduplicator:
    def __init__(self, max_size: int = 1000):
        self.seen = set()
        self.max_size = max_size

    def is_duplicate(self, event: dict) -> bool:
        # DEÄÄ°ÅTÄ°: Daha gÃ¼venilir bir UID iÃ§in event'in tamamÄ±nÄ± kullanabiliriz
        uid_str = json.dumps(event, sort_keys=True)
        if uid_str in self.seen: return True
        self.seen.add(uid_str)
        if len(self.seen) > self.max_size:
            self.seen = set(list(self.seen)[-self.max_size:])
        return False

class WebSocketRedundantManager:
    # DEÄÄ°ÅTÄ°: ArtÄ±k sadece listenkey listesi yerine (key, user_id, api_id) iÃ§eren bir dict listesi alÄ±yor
    def __init__(self, pool, initial_key_info: list, url: str):
        self.pool = pool
        self.key_info = initial_key_info
        # YENÄ°: listenKey'den user_id/api_id'ye hÄ±zlÄ± eriÅŸim iÃ§in bir map (sÃ¶zlÃ¼k)
        self.key_to_user_map = {info['stream_key']: info for info in self.key_info}
        self.listenkeys = list(self.key_to_user_map.keys())
        self.url = url
        self.dedup = Deduplicator()
        self.active_connections = {}
        self.base_ws_id = None
        # YENÄ°: Veri kuyruklarÄ± ve writer task'larÄ±
        self.balance_update_queue = {}
        self.order_update_queue = []
        self.writer_tasks = []

    async def start(self, existing_ws_id: int = None):
        if not self.listenkeys:
            logging.warning("BaÅŸlatÄ±lacak listenKey bulunmadÄ±ÄŸÄ± iÃ§in WebSocketRedundantManager baÅŸlatÄ±lmadÄ±.")
            return
        await self._open_redundant_pair(self.listenkeys, existing_ws_id)
        await attach_listenkeys_to_ws(self.pool, self.base_ws_id, self.listenkeys)
        # YENÄ°: Writer gÃ¶revlerini baÅŸlatÄ±yoruz
        self.writer_tasks.append(asyncio.create_task(self._balance_batch_writer()))
        self.writer_tasks.append(asyncio.create_task(self._order_batch_writer()))
        logging.info(f"âœ… [WS ID: {self.base_ws_id}] Bakiye ve emir yazÄ±cÄ±larÄ± baÅŸlatÄ±ldÄ±.")

    # DEÄÄ°ÅTÄ°: new_listenkeys yerine new_key_info alÄ±yor
    async def update_and_restart(self, new_key_info: list):
        logging.info(f"ğŸ”„ WS ID {self.base_ws_id} iÃ§in overlap/restart sÃ¼reci baÅŸlatÄ±lÄ±yor. Yeni anahtar sayÄ±sÄ±: {len(new_key_info)}")
        if not new_key_info:
            await self.shutdown()
            return
        
        # YENÄ°: Ã–nce eski yazÄ±cÄ±larÄ± ve baÄŸlantÄ±larÄ± durdur
        for task in self.writer_tasks:
            task.cancel()
        self.writer_tasks.clear()
        old_connections = list(self.active_connections.values())
        self.active_connections.clear()

        # YENÄ°: Yeni anahtar bilgileriyle yeniden baÅŸlat
        self.key_info = new_key_info
        self.key_to_user_map = {info['stream_key']: info for info in self.key_info}
        self.listenkeys = list(self.key_to_user_map.keys())
        await self.start(existing_ws_id=self.base_ws_id)

        await asyncio.sleep(5)
        logging.info(f"â³ Overlap sÃ¼resi doldu. WS ID {self.base_ws_id} iÃ§in eski baÄŸlantÄ±lar kapatÄ±lÄ±yor.")
        for ws, task in old_connections:
            if not task.done(): task.cancel()
            await self._close_ws(ws)
        logging.info(f"âœ… WS ID {self.base_ws_id} iÃ§in overlap/restart tamamlandÄ±.")

    async def shutdown(self):
        logging.info(f"ğŸ—‘ï¸ WS ID {self.base_ws_id} iÃ§in hiÃ§ anahtar kalmadÄ±. KapatÄ±lÄ±yor.")
        for task in self.writer_tasks: # YENÄ°: YazÄ±cÄ±larÄ± durdur
            task.cancel()
        for ws, task in self.active_connections.values():
            if not task.done(): task.cancel()
            await self._close_ws(ws)
        self.active_connections.clear()
        if self.base_ws_id:
            await ws_db.delete_ws(self.pool, self.base_ws_id)
            logging.info(f"âœ… WS ID {self.base_ws_id} DB'den baÅŸarÄ±yla silindi.")
            self.base_ws_id = None
        
    async def _open_redundant_pair(self, listenkeys: list, base_id: int = None):
        streams = "/".join(listenkeys)
        url = f"{self.url}/stream?streams={streams}"
        if base_id is None:
            self.base_ws_id = await ws_db.insert_ws(self.pool, "redundant-group-futures", "binance", url)
        else:
            self.base_ws_id = base_id
        await ws_db.update_ws_url_and_count(self.pool, self.base_ws_id, url, len(listenkeys))
        for i in range(2):
            name = f"ws_{self.base_ws_id}_redundant-{i}"
            try:
                conn = await websockets.connect(url, ping_interval=20, ping_timeout=10)
                task = asyncio.create_task(self._listen(conn, name))
                self.active_connections[name] = (conn, task)
                logging.info(f"ğŸŒ [{name}] baÄŸlantÄ± aÃ§Ä±ldÄ±.")
            except Exception as e:
                logging.error(f"âŒ [{name}] baÄŸlantÄ± hatasÄ±: {e}")

    # DEÄÄ°ÅTÄ°: _listen artÄ±k veriyi iÅŸlemek iÃ§in _handle_event'e yÃ¶nlendiriyor
    async def _listen(self, ws, role: str):
        try:
            async for msg in ws:
                data = json.loads(msg)
                event_data = data.get('data', {})
                if 'e' in event_data and not self.dedup.is_duplicate(event_data):
                    # YÃ¶nlendirme yapÄ±lÄ±yor
                    asyncio.create_task(self._handle_event(data))
        except websockets.exceptions.ConnectionClosed:
            logging.warning(f"ğŸ”Œ [{role}] baÄŸlantÄ±sÄ± kapandÄ±.")
        except Exception as e:
            logging.error(f"[{role}] dinleme hatasÄ±: {e}", exc_info=True)

    async def _handle_event(self, event: dict):
        stream_key = event.get('stream')
        user_info = self.key_to_user_map.get(stream_key)
        if not user_info: return

        event_data = event.get('data')
        event_type = event_data.get('e')

        try:
            if event_type == 'ACCOUNT_UPDATE':
                self._handle_account_update(event_data, user_info)
            elif event_type == 'ORDER_TRADE_UPDATE':
                # ArtÄ±k async olduÄŸu iÃ§in await ile Ã§aÄŸÄ±rÄ±yoruz
                await self._handle_order_update(event_data, user_info)
        except Exception as e:
            logging.error(f"âŒ Olay iÅŸlenirken hata (event_type: {event_type}): {e}", exc_info=True)
    # YENÄ°: Bakiye gÃ¼ncelleme olayÄ±nÄ± iÅŸler ve kuyruÄŸa atar
    def _handle_account_update(self, data: dict, user_info: dict):
        update_info = data.get('a', {})
        if not update_info.get('B'): return
        
        user_id, api_id = user_info['user_id'], user_info['api_id']
        self.balance_update_queue[(user_id, api_id)] = {
            "user_id": user_id, "api_id": api_id,
            "assets": update_info.get('B', [])
        }
        logging.debug(f"Futures bakiye gÃ¼ncellemesi kuyruÄŸa eklendi: user_id={user_id}")

    # YENÄ°: Emir gÃ¼ncelleme olayÄ±nÄ± iÅŸler ve kuyruÄŸa atar
    async def _handle_order_update(self, data: dict, user_info: dict):
        order_info = data.get('o', {})

        # 1. Komisyon miktarÄ±nÄ± ve birimini al
        commission_amount = Decimal(order_info.get("n", "0"))
        commission_asset = order_info.get("N")  # Komisyon birimi (Ã¶rn: "BNB", "USDT")
        commission_in_usdt = commission_amount

        # 2. EÄŸer birim USDT deÄŸilse ve miktar sÄ±fÄ±rdan bÃ¼yÃ¼kse Ã§evir
        if commission_asset and commission_asset.upper() != "USDT" and commission_amount > 0:
            try:
                conversion_symbol = f"{commission_asset.upper()}USDT"
                # FiyatÄ± price_cache'den al (komisyon varlÄ±klarÄ± spot'ta iÅŸlem gÃ¶rÃ¼r)
                price = await get_price(conversion_symbol, "spot")

                if price and price > 0:
                    commission_in_usdt = commission_amount * Decimal(str(price))
                    logging.info(f"ğŸ’° [Futures WS] Komisyon dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼: {commission_amount} {commission_asset} -> {commission_in_usdt:.6f} USDT")
                else:
                    logging.warning(f"âš ï¸ [Futures WS] {conversion_symbol} iÃ§in fiyat alÄ±namadÄ±. Komisyon orijinal deÄŸeriyle kaydedilecek.")
            except Exception as e:
                logging.error(f"âŒ [Futures WS] Komisyon dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±: {e}. Komisyon orijinal deÄŸeriyle kaydedilecek.")

        # 3. VeritabanÄ±na yazÄ±lacak veriyi hazÄ±rla
        order_data = {
            "user_id": user_info['user_id'],
            "api_id": user_info['api_id'],
            "symbol": order_info.get("s"),
            "client_order_id": order_info.get("c"),
            "side": order_info.get("S"),
            "position_side": order_info.get("ps"),
            "status": order_info.get("X"),
            "price": Decimal(order_info.get("p", "0")),
            "executed_quantity": Decimal(order_info.get("z", "0")),
            "commission": commission_in_usdt,  # <-- GÃœNCELLENDÄ°
            "realized_profit": Decimal(order_info.get("rp", "0")),
            "order_id": order_info.get("i"),
            "event_time": order_info.get("T")
        }
        self.order_update_queue.append(order_data)
        logging.debug(f"Futures emir gÃ¼ncellemesi kuyruÄŸa eklendi: user_id={user_info['user_id']}, order_id={order_data['order_id']}")



    # YENÄ°: Bakiye kuyruÄŸunu DB'ye yazar
    async def _balance_batch_writer(self):
        while True:
            await asyncio.sleep(5)
            if self.balance_update_queue:
                queue_copy = list(self.balance_update_queue.values())
                self.balance_update_queue.clear()
                try:
                    await batch_upsert_futures_balances(self.pool, queue_copy)
                except Exception as e:
                    logging.error(f"âŒ [Batch] Futures Bakiye DB gÃ¼ncellemesi baÅŸarÄ±sÄ±z: {e}", exc_info=True)

    # YENÄ°: Emir kuyruÄŸunu DB'ye yazar
    async def _order_batch_writer(self):
        while True:
            await asyncio.sleep(3)
            if self.order_update_queue:
                queue_copy = self.order_update_queue.copy()
                self.order_update_queue.clear()
                try:
                    await batch_upsert_futures_orders(self.pool, queue_copy)
                except Exception as e:
                    logging.error(f"âŒ [Batch] Futures Emir DB gÃ¼ncellemesi baÅŸarÄ±sÄ±z: {e}", exc_info=True)

    async def _close_ws(self, ws):
            # DÃœZELTME: 'ws.closed' kontrolÃ¼ kaldÄ±rÄ±ldÄ±.
            # ws.close() metodu zaten kapalÄ± bir baÄŸlantÄ± iÃ§in hata vermez.
            if ws:
                try:
                    await ws.close()
                except Exception: 
                    pass

class DynamicListenerManager:
    def __init__(self, pool, url="wss://fstream.binance.com", max_per_ws=100):
        self.pool = pool
        self.url = url
        self.max_per_ws = max_per_ws
        self.active_managers = {}
        self.new_key_queue = asyncio.Queue()

    # ws_service.py DOSYASINA EKLENECEK KOD
# DynamicListenerManager sÄ±nÄ±fÄ±nÄ±n iÃ§ine ekleyin

    async def _listen_for_db_events(self):
        """
        PostgreSQL'in LISTEN/NOTIFY mekanizmasÄ±nÄ± kullanarak veritabanÄ± olaylarÄ±nÄ±
        sÃ¼rekli olarak dinler ve ilgili callback fonksiyonunu tetikler.
        """
        channel_name = "streamkey_events" # DB trigger'Ä±nÄ±zÄ±n bildirim gÃ¶nderdiÄŸi kanal
        logging.info(f"ğŸ‘‚ VeritabanÄ± '{channel_name}' kanalÄ± dinlenmeye baÅŸlanÄ±yor...")
        
        # Bu metodun sÃ¼rekli Ã§alÄ±ÅŸmasÄ± iÃ§in bir sonsuz dÃ¶ngÃ¼ gerekiyor.
        # asyncpg, add_listener'Ä± baÄŸlantÄ± aÃ§Ä±k kaldÄ±ÄŸÄ± sÃ¼rece Ã§alÄ±ÅŸtÄ±rÄ±r.
        # Bu yÃ¼zden baÄŸlantÄ±yÄ± aÃ§Ä±k tutmalÄ±yÄ±z.
        while True:
            try:
                conn = await self.pool.acquire()
                await conn.add_listener(channel_name, self._db_event_callback)
                
                # BaÄŸlantÄ±yÄ± ve listener'Ä± aktif tutmak iÃ§in bekliyoruz.
                # EÄŸer baÄŸlantÄ± koparsa, dÃ¶ngÃ¼ yeniden baÅŸlayacak ve
                # yeni bir baÄŸlantÄ± ile listener tekrar kurulacak.
                while True:
                    await asyncio.sleep(3600) # Periyodik olarak bekle
            except Exception as e:
                logging.error(f"âŒ VeritabanÄ± dinleyicisinde hata: {e}. Yeniden baÄŸlanÄ±lÄ±yor...", exc_info=True)
                # BaÄŸlantÄ±yÄ± release et (eÄŸer varsa) ve kÄ±sa bir sÃ¼re sonra tekrar dene
                if 'conn' in locals() and not conn.is_closed():
                    try:
                        await self.pool.release(conn)
                    except Exception as release_error:
                        logging.error(f"BaÄŸlantÄ± bÄ±rakÄ±lÄ±rken hata: {release_error}")
                await asyncio.sleep(5)

    async def run(self):
        await self._initialize_from_db()
        await asyncio.gather(self._listen_for_db_events(), self._process_new_key_buffer())

    # GÃœNCELLENDÄ°: Bu fonksiyon artÄ±k sahipsiz 'new' key'leri de baÅŸlatÄ±yor.
    # ws_service.py iÃ§indeki DynamicListenerManager sÄ±nÄ±fÄ±na ait fonksiyon
    async def _initialize_from_db(self):
        """
        Sistem baÅŸlangÄ±cÄ±nda temiz bir kurulum yapar.
        1. Ã–nceki Ã§alÄ±ÅŸtÄ±rmadan kalma tÃ¼m 'futures' WS kayÄ±tlarÄ±nÄ± temizler. (EN GÃœVENÄ°LÄ°R YÃ–NTEM)
        2. YENÄ°: Sadece 'new' veya 'active' durumundaki geÃ§erli futures anahtarlarÄ±nÄ±n ws_id'lerini sÄ±fÄ±rlar.
        3. Bu anahtarlar iÃ§in sÄ±fÄ±rdan WebSocket gruplarÄ± oluÅŸturur.
        """
        logging.info("ğŸš€ Sistem baÅŸlangÄ±cÄ±: Temiz bir kurulum iÃ§in veritabanÄ± hazÄ±rlanÄ±yor...")
        
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                # 1. AdÄ±m: Eski ve geÃ§ersiz 'futures' WS kayÄ±tlarÄ±nÄ± temizle
                logging.info("  -> Eski 'futures' WebSocket kayÄ±tlarÄ± siliniyor...")
                await conn.execute("DELETE FROM websocket_connections WHERE name LIKE '%futures%'")
                
                # 2. AdÄ±m: Futures anahtarlarÄ±nÄ±n ws_id'lerini sÄ±fÄ±rla (GÃœNCELLENDÄ°)
                logging.info("  -> 'new'/'active' durumundaki Futures anahtarlarÄ±nÄ±n eski baÄŸlantÄ± ID'leri temizleniyor...")
                await conn.execute("""
                    UPDATE stream_keys 
                    SET ws_id = NULL 
                    WHERE status IN ('new', 'active') AND is_futures_enabled = TRUE
                """)

                # 3. AdÄ±m: KurulmasÄ± gereken TÃœM anahtarlarÄ± topla
                logging.info("  -> 'new' ve 'active' durumundaki tÃ¼m futures anahtarlarÄ± toplanÄ±yor...")
                keys_to_start = await conn.fetch("""
                    SELECT user_id, api_id, stream_key 
                    FROM stream_keys 
                    WHERE is_futures_enabled = TRUE AND status IN ('new', 'active')
                """)

        if not keys_to_start:
            logging.info("âœ… BaÅŸlatÄ±lacak aktif veya yeni futures anahtarÄ± bulunamadÄ±.")
        else:
            logging.info(f"â• {len(keys_to_start)} adet futures anahtarÄ± bulundu. WebSocket gruplarÄ± oluÅŸturulacak...")
            events_to_add = [
                {'stream_key': key['stream_key'], 'user_id': key['user_id'], 'api_id': key['api_id']}
                for key in keys_to_start
            ]
            await self._place_new_keys_intelligently(events_to_add)

        logging.info("âœ… BaÅŸlangÄ±Ã§ senkronizasyonu tamamlandÄ±.")


    def _db_event_callback(self, conn, pid, channel, payload):
        logging.info(f"ğŸ“¦ DB'den yeni olay alÄ±ndÄ±: {payload}")
        event = json.loads(payload)
        status = event.get("status")
        if status == 'new':
            self.new_key_queue.put_nowait(event)
        elif status in ('remove', 'expired', 'error'):
            asyncio.create_task(self._handle_remove_key(event))

    async def _process_new_key_buffer(self):
        while True:
            first_event = await self.new_key_queue.get()
            batch = [first_event] # DEÄÄ°ÅTÄ°: ArtÄ±k key yerine tÃ¼m event objesini tutuyoruz
            while not self.new_key_queue.empty():
                batch.append(self.new_key_queue.get_nowait())
            
            logging.info(f"â• Toplu ekleme iÅŸlemi: {len(batch)} adet yeni anahtar iÅŸlenecek.")
            await self._place_new_keys_intelligently(batch)

    # DEÄÄ°ÅTÄ°: ArtÄ±k key listesi yerine event listesi alÄ±yor
    async def _place_new_keys_intelligently(self, events_to_add: list):
        for ws_id, manager in self.active_managers.items():
            if not events_to_add: break
            
            current_count = len(manager.listenkeys)
            space_available = self.max_per_ws - current_count
            if space_available > 0:
                events_for_this_manager = events_to_add[:space_available]
                events_to_add = events_to_add[space_available:]
                
                keys_for_this_manager = [event['stream_key'] for event in events_for_this_manager]
                logging.info(f"  -> {len(keys_for_this_manager)} anahtar mevcut WS ID {ws_id} grubuna ekleniyor.")
                await attach_listenkeys_to_ws(self.pool, ws_id, keys_for_this_manager)
                updated_keys_records = await ws_db.get_streamkeys_by_ws(self.pool, ws_id)
                await manager.update_and_restart([dict(rec) for rec in updated_keys_records])

        while events_to_add:
            events_for_new_manager = events_to_add[:self.max_per_ws]
            events_to_add = events_to_add[self.max_per_ws:]

            # YENÄ°: Gelen event'lerden key_info listesini oluÅŸtur
            key_info_list = [{'stream_key': e['stream_key'], 'user_id': e['user_id'], 'api_id': e['api_id']} for e in events_for_new_manager]
            logging.info(f"  -> Kapasitesi olan grup kalmadÄ±. {len(key_info_list)} anahtar iÃ§in yeni WS grubu oluÅŸturuluyor.")
            new_manager = WebSocketRedundantManager(self.pool, key_info_list, self.url)
            await new_manager.start()
            if new_manager.base_ws_id:
                self.active_managers[new_manager.base_ws_id] = new_manager
            logging.info(f"âœ… Yeni WS grubu {new_manager.base_ws_id} oluÅŸturuldu.")

    async def _handle_remove_key(self, event: dict):
        ws_id, listen_key = event.get("ws_id"), event.get("stream_key")
        logging.info(f"â– Ã‡Ä±karma iÅŸlemi baÅŸlatÄ±lÄ±yor: {listen_key} (WS ID: {ws_id})")
        if not ws_id:
            logging.error(f"âŒ Ã‡Ä±karma hatasÄ±: {listen_key} iÃ§in ws_id bilgisi olayda bulunamadÄ±!")
            return

        manager = self.active_managers.get(ws_id)
        if not manager:
            logging.warning(f"âš ï¸ WS ID {ws_id} iÃ§in aktif yÃ¶netici bulunamadÄ±.")
            await ws_db.set_stream_key_closed_and_null_ws_id(self.pool, listen_key)
            return

        # DEÄÄ°ÅTÄ°: Kalan anahtarlarÄ±n tam bilgisini al
        updated_keys_records = await ws_db.get_streamkeys_by_ws(self.pool, ws_id)
        await manager.update_and_restart([dict(rec) for rec in updated_keys_records])
        await ws_db.set_stream_key_closed_and_null_ws_id(self.pool, listen_key)
        logging.info(f"âœ… DB GÃ¼ncellemesi: {listen_key} durumu 'closed' ve ws_id NULL olarak ayarlandÄ±.")

        if manager.base_ws_id is None:
            self.active_managers.pop(ws_id, None)

async def main():
    # YENÄ°: Hata yakalama bloÄŸu eklendi
    try:
        pool = await config.get_async_pool()
        if not pool:
            logging.error("âŒ VeritabanÄ± baÄŸlantÄ± havuzu oluÅŸturulamadÄ±. Ã‡Ä±kÄ±lÄ±yor.")
            return
        
        logging.info("DynamicListenerManager baÅŸlatÄ±lÄ±yor...")
        manager = DynamicListenerManager(pool, max_per_ws=100)
        await manager.run()
    except Exception as e:
        # Hata oluÅŸursa, tÃ¼m detaylarÄ±yla logla
        logging.error("âŒ FUTURES SERVÄ°SÄ°NDE BEKLENMEDÄ°K BÄ°R HATA OLUÅTU!", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())

if __name__ == "__main__":
    asyncio.run(main())